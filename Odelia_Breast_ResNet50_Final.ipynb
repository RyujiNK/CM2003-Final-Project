{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Odelia Breast MRI Challenge - ResNet50",
   "id": "96d38ade876bec27"
  },
  {
   "cell_type": "markdown",
   "id": "3bc1fe17",
   "metadata": {},
   "source": [
    "## <a id='imports'></a>1. Imports & Setup\n",
    "_Standard libraries, Torch, Torchvision, utilities._"
   ]
  },
  {
   "cell_type": "code",
   "id": "b94ed758",
   "metadata": {},
   "source": [
    "# Cell 1: Import Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "from collections import Counter\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# MONAI imports\n",
    "from monai.data import CacheDataset, list_data_collate\n",
    "from monai.transforms import (\n",
    "    Compose, LoadImaged, EnsureChannelFirstd, Orientationd,\n",
    "    Spacingd, ScaleIntensityRanged, ResizeWithPadOrCropd,\n",
    "    EnsureTyped, ConcatItemsd,\n",
    "    RandRotate90d, RandFlipd, RandZoomd, RandGaussianNoised\n",
    ")\n",
    "from monai.networks.nets import resnet50\n",
    "\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "6dba4823",
   "metadata": {},
   "source": [
    "## <a id='config'></a>2. Configuration\n",
    "_Hyperparameters, paths, and class mapping._\n",
    "\n",
    "- `NUM_CLASSES = 3` (0: no lesion, 1: benign, 2: malignant)\n",
    "- `TARGET_CLASS_FOR_OPS = 2` (malignant for operating-point metrics)"
   ]
  },
  {
   "cell_type": "code",
   "id": "03d661c1",
   "metadata": {},
   "source": [
    "# Cell 2: Configuration\n",
    "from pathlib import Path\n",
    "\n",
    "# Paths (matching working notebook)\n",
    "ROOT_DIR = r\"C:\\Users\\NK\\PycharmProjects\\DeepLearningProject\\dataset_downloaded\"\n",
    "CSV_ANNOT = r\"C:\\Users\\NK\\PycharmProjects\\DeepLearningProject\\dataset_downloaded\\UMCU\\metadata_unilateral\\annotation.csv\"\n",
    "CSV_SPLIT = r\"C:\\Users\\NK\\PycharmProjects\\DeepLearningProject\\dataset_downloaded\\UMCU\\metadata_unilateral\\split.csv\"\n",
    "IMAGES_ROOT = r\"C:\\Users\\NK\\PycharmProjects\\DeepLearningProject\\dataset_downloaded\\UMCU\\data_unilateral\"\n",
    "\n",
    "# Training config\n",
    "BATCH_SIZE = 1\n",
    "EPOCHS = 20\n",
    "LR = 5e-5\n",
    "WEIGHT_DECAY = 1e-4\n",
    "NUM_WORKERS = 0\n",
    "PIN_MEMORY = True\n",
    "...\n",
    "CHANNEL_KEYS = [\"T2\", \"Pre\", \"Post_1\", \"Post_2\", \"Post_3\"]\n",
    "\n",
    "# 3-class setup\n",
    "# 0 = no lesion, 1 = benign, 2 = malignant\n",
    "NUM_CLASSES = 3\n",
    "# For operating point metrics (Spec@90%Sens, Sens@90%Spec), target class = malignant\n",
    "TARGET_CLASS_FOR_OPS = 2\n",
    "\n",
    "TARGET_SPACING = (0.7, 0.7, 3.0)\n",
    "TARGET_SHAPE = (96, 224, 224)\n",
    "\n",
    "# Verify paths\n",
    "assert Path(CSV_ANNOT).exists(), f\"Missing: {CSV_ANNOT}\"\n",
    "assert Path(CSV_SPLIT).exists(), f\"Missing: {CSV_SPLIT}\"\n",
    "assert Path(IMAGES_ROOT).exists(), f\"Missing: {IMAGES_ROOT}\"\n",
    "\n",
    "# Device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "print(f\"All paths verified\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f5adc6cc",
   "metadata": {},
   "source": [
    "## <a id='data'></a>3. Data Loading & Preprocessing\n",
    "_Read CSVs, build datasets/dataloaders, apply transforms._"
   ]
  },
  {
   "cell_type": "code",
   "id": "fc1cd1d6",
   "metadata": {},
   "source": [
    "# Cell 3: Load CSV Files\n",
    "import pandas as pd\n",
    "\n",
    "# Load annotation and split data\n",
    "df_annot = pd.read_csv(CSV_ANNOT)\n",
    "df_split = pd.read_csv(CSV_SPLIT)\n",
    "\n",
    "# Check column names\n",
    "print(\"Annotation columns:\", df_annot.columns.tolist())\n",
    "print(\"Split columns:\", df_split.columns.tolist())\n",
    "\n",
    "# Merge using UID (common column in both CSVs)\n",
    "df = pd.merge(df_annot, df_split, on=\"UID\")\n",
    "\n",
    "df = df.rename(columns={\"Split\": \"split\"})\n",
    "\n",
    "print(f\"\\nLoaded {len(df)} samples\")\n",
    "print(f\"Merged columns: {df.columns.tolist()}\")\n",
    "print(f\"\\nLesion distribution:\")\n",
    "print(df[\"Lesion\"].value_counts())\n",
    "print(f\"\\nSplit distribution:\")\n",
    "print(df[\"split\"].value_counts())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "dfa4857c",
   "metadata": {},
   "source": [
    "# Cell 4: Build Sample Dictionaries\n",
    "def build_samples(df, images_root):\n",
    "    samples = []\n",
    "    skipped = 0\n",
    "\n",
    "    images_root_path = Path(images_root)\n",
    "    has_laterality = 'Laterality' in df.columns\n",
    "\n",
    "    # Check raw Lesion values before processing\n",
    "    print(\"Checking Lesion column values:\")\n",
    "    print(f\"Unique values: {df['Lesion'].unique()}\")\n",
    "    print(f\"Value counts:\\n{df['Lesion'].value_counts()}\")\n",
    "    print(f\"\\nFirst 10 raw Lesion values:\")\n",
    "    for i, val in enumerate(df['Lesion'].head(10)):\n",
    "        print(f\"  {i}: '{val}' (type: {type(val).__name__})\")\n",
    "\n",
    "    label_debug = {\"0_no_lesion\": 0, \"1_benign\": 0, \"2_malignant\": 0, \"invalid\": 0}\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        uid = row[\"UID\"]\n",
    "\n",
    "        if has_laterality:\n",
    "            lat = str(row[\"Laterality\"]).strip()\n",
    "            patient_id = f\"{uid}_{lat}\"\n",
    "        else:\n",
    "            patient_id = str(uid)\n",
    "\n",
    "        subject_dir = images_root_path / str(uid)\n",
    "        if has_laterality:\n",
    "            subject_dir = subject_dir / lat\n",
    "\n",
    "        if not subject_dir.exists():\n",
    "            skipped += 1\n",
    "            continue\n",
    "\n",
    "        \n",
    "        lesion_raw = row[\"Lesion\"]\n",
    "        try:\n",
    "            lesion_int = int(lesion_raw)\n",
    "        except Exception:\n",
    "            lesion_int = None\n",
    "\n",
    "        if lesion_int not in (0, 1, 2):\n",
    "            label_debug[\"invalid\"] += 1\n",
    "            \n",
    "            skipped += 1\n",
    "            continue\n",
    "\n",
    "        if lesion_int == 0:\n",
    "            label_debug[\"0_no_lesion\"] += 1\n",
    "        elif lesion_int == 1:\n",
    "            label_debug[\"1_benign\"] += 1\n",
    "        else:\n",
    "            label_debug[\"2_malignant\"] += 1\n",
    "\n",
    "        split_value = str(row[\"split\"]).strip()\n",
    "\n",
    "        sample = {\n",
    "            \"label\": lesion_int,                 # 0/1/2 (no lesion / benign / malignant)\n",
    "            \"subject_id\": str(patient_id),\n",
    "            \"split\": split_value\n",
    "        }\n",
    "\n",
    "        \n",
    "        for key in CHANNEL_KEYS:\n",
    "            nii_path = subject_dir / f\"{key}.nii.gz\"\n",
    "            if nii_path.exists():\n",
    "                sample[key] = str(nii_path)\n",
    "\n",
    "        samples.append(sample)\n",
    "\n",
    "    print(\"\\nLabel parse summary:\", label_debug)\n",
    "    print(f\"Skipped {skipped} samples (missing dir or invalid label).\")\n",
    "    return samples\n",
    "\n",
    "\n",
    "all_samples = build_samples(df, IMAGES_ROOT)\n",
    "print(f\"\\nBuilt {len(all_samples)} samples (allowing missing modalities)\")\n",
    "\n",
    "# Check label distribution\n",
    "if all_samples:\n",
    "    import collections\n",
    "    built_labels = collections.Counter(s['label'] for s in all_samples)\n",
    "    print(f\"\\n✓ Final label distribution: {dict(built_labels)}\")\n",
    "    \n",
    "    by_split_label = {}\n",
    "    for s in all_samples:\n",
    "        k = (s['split'], s['label'])\n",
    "        by_split_label[k] = by_split_label.get(k, 0) + 1\n",
    "    print(f\"Per-split label counts: {by_split_label}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3748e8d9",
   "metadata": {},
   "source": [
    "# Cell 5a: Split Data Using Provided Splits\n",
    "\n",
    "def normalize_split(value) -> str:\n",
    "    s = str(value).strip().lower()\n",
    "    if s in {\"0\", \"train\"}:\n",
    "        return \"train\"\n",
    "    if s in {\"1\", \"val\", \"valid\", \"validation\"}:\n",
    "        return \"val\"\n",
    "    if s in {\"2\", \"test\", \"testing\"}:\n",
    "        return \"test\"\n",
    "    return s \n",
    "\n",
    "# Quick overview of raw values\n",
    "raw_splits = sorted({str(s.get(\"split\")).strip() for s in all_samples})\n",
    "print(f\"Raw split values found: {raw_splits}\")\n",
    "\n",
    "# Normalize all splits and bucket in one pass\n",
    "buckets = {\"train\": [], \"val\": [], \"test\": []}\n",
    "for s in all_samples:\n",
    "    s[\"split\"] = normalize_split(s.get(\"split\", \"\"))\n",
    "    if s[\"split\"] in buckets:\n",
    "        buckets[s[\"split\"]].append(s)\n",
    "\n",
    "train_list, val_list, test_list = buckets[\"train\"], buckets[\"val\"], buckets[\"test\"]\n",
    "\n",
    "def label_counts(samples):\n",
    "    return dict(Counter(s[\"label\"] for s in samples))\n",
    "\n",
    "print(f\"\\nTrain: {len(train_list)} | Val: {len(val_list)} | Test: {len(test_list)}\")\n",
    "if train_list:\n",
    "    print(\"Train distribution:\", label_counts(train_list))\n",
    "if val_list:\n",
    "    print(\"Val distribution:  \", label_counts(val_list))\n",
    "if test_list:\n",
    "    print(\"Test distribution: \", label_counts(test_list))\n",
    "else:\n",
    "    print(\"No test samples\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "57cb15cf",
   "metadata": {},
   "source": [
    "# Cell 5b: Balanced Sampling Setup\n",
    "from collections import Counter\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "\n",
    "# Calculate sample weights for balanced sampling\n",
    "train_labels = [s[\"label\"] for s in train_list]\n",
    "class_counts = Counter(train_labels)\n",
    "\n",
    "# Weight each sample inversely to its class frequency\n",
    "sample_weights = [1.0 / class_counts[label] for label in train_labels]\n",
    "sampler = WeightedRandomSampler(\n",
    "    weights=sample_weights,\n",
    "    num_samples=len(train_list),\n",
    "    replacement=True\n",
    ")\n",
    "\n",
    "print(f\"Original class counts: {dict(class_counts)}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "881df060",
   "metadata": {},
   "source": [
    "# Cell 6: Missing Modality Handler\n",
    "class FillMissingModalitiesd:\n",
    "    def __init__(self, keys, ref_key=\"Pre\"): \n",
    "        self.keys = keys\n",
    "        self.ref_key = ref_key\n",
    "\n",
    "    def __call__(self, data):\n",
    "        ref_shape = data[self.ref_key].shape\n",
    "        for key in self.keys:\n",
    "            if key not in data or data[key] is None:\n",
    "                data[key] = torch.zeros(ref_shape, dtype=torch.float32)\n",
    "        return data"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c056019e",
   "metadata": {},
   "source": [
    "# Cell 7: Data Transforms\n",
    "def make_transforms(is_train: bool) -> Compose:\n",
    "    common = [\n",
    "        LoadImaged(keys=CHANNEL_KEYS, image_only=False, ensure_channel_first=False, allow_missing_keys=True),\n",
    "        EnsureChannelFirstd(keys=CHANNEL_KEYS, allow_missing_keys=True),\n",
    "        Orientationd(keys=CHANNEL_KEYS, axcodes=\"RAS\", allow_missing_keys=True),\n",
    "        Spacingd(keys=CHANNEL_KEYS, pixdim=TARGET_SPACING, mode=(\"bilinear\",) * len(CHANNEL_KEYS),\n",
    "                 allow_missing_keys=True),\n",
    "        ScaleIntensityRanged(\n",
    "            keys=CHANNEL_KEYS, a_min=-100, a_max=1000, b_min=0.0, b_max=1.0, clip=True, allow_missing_keys=True\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    # Add augmentation for training only\n",
    "    if is_train:\n",
    "        augmentation = [\n",
    "            RandRotate90d(keys=CHANNEL_KEYS, prob=0.7, spatial_axes=(1, 2)),\n",
    "            RandFlipd(keys=CHANNEL_KEYS, prob=0.5, spatial_axis=1),\n",
    "            RandFlipd(keys=CHANNEL_KEYS, prob=0.5, spatial_axis=2),\n",
    "            RandZoomd(keys=CHANNEL_KEYS, prob=0.3, min_zoom=0.9, max_zoom=1.1),\n",
    "            RandGaussianNoised(keys=CHANNEL_KEYS, prob=0.2, mean=0.0, std=0.1),\n",
    "        ]\n",
    "        common.extend(augmentation)\n",
    "\n",
    "    common.extend([\n",
    "        ResizeWithPadOrCropd(keys=CHANNEL_KEYS, spatial_size=TARGET_SHAPE, allow_missing_keys=True),\n",
    "        EnsureTyped(keys=CHANNEL_KEYS + [\"label\"]),\n",
    "        FillMissingModalitiesd(keys=CHANNEL_KEYS, ref_key=\"Pre\"), \n",
    "        ConcatItemsd(keys=CHANNEL_KEYS, name=\"image\", dim=0),\n",
    "    ])\n",
    "\n",
    "    return Compose(common)\n",
    "\n",
    "\n",
    "print(\"Transforms created (with augmentation for training)\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "45bbae5a",
   "metadata": {},
   "source": [
    "# Cell 8: Build Cached DataLoaders\n",
    "CACHE_RATE = 0.5 \n",
    "\n",
    "print(\"Building cached datasets\")\n",
    "\n",
    "train_ds = CacheDataset(\n",
    "    train_list,\n",
    "    transform=make_transforms(is_train=True),\n",
    "    cache_rate=CACHE_RATE,\n",
    "    num_workers=4\n",
    ")\n",
    "\n",
    "val_ds = CacheDataset(\n",
    "    val_list,\n",
    "    transform=make_transforms(is_train=False),\n",
    "    cache_rate=1.0,\n",
    "    num_workers=4\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    sampler=sampler,\n",
    "    shuffle=True,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=PIN_MEMORY,\n",
    "    collate_fn=list_data_collate\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_ds,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=PIN_MEMORY,\n",
    "    collate_fn=list_data_collate\n",
    ")\n",
    "\n",
    "print(f\" DataLoaders ready:\")\n",
    "print(f\"  Train: {len(train_loader)} batches\")\n",
    "print(f\"  Val:   {len(val_loader)} batches\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9e73ac4f",
   "metadata": {},
   "source": [
    "# Cell 9: Test DataLoader\n",
    "print(\"Testing data loading...\")\n",
    "batch = next(iter(train_loader))\n",
    "print(f\"Batch image shape: {batch['image'].shape}\")  # (B, C, D, H, W)\n",
    "print(f\"Batch label shape: {batch['label'].shape}\")  # (B,)\n",
    "print(f\"Label values: {batch['label'].tolist()}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "54085a1f",
   "metadata": {},
   "source": [
    "# Cell 10: Adjust class weights for extreme imbalance\n",
    "from collections import Counter\n",
    "\n",
    "train_labels = [s[\"label\"] for s in train_list]\n",
    "class_counts = Counter(train_labels)\n",
    "total = len(train_labels)\n",
    "\n",
    "# Inverse-frequency weights\n",
    "weights = []\n",
    "for i in range(NUM_CLASSES):\n",
    "    count = class_counts.get(i, 0)\n",
    "    if count == 0:\n",
    "        w = 1.0\n",
    "    else:\n",
    "        w = total / (NUM_CLASSES * count)\n",
    "    weights.append(w)\n",
    "\n",
    "if NUM_CLASSES >= 3:\n",
    "    weights[2] *= 1.5\n",
    "\n",
    "class_weights_tensor = torch.tensor(weights, dtype=torch.float32).to(device)\n",
    "print(f\"Class counts: {dict(class_counts)}\")\n",
    "print(f\"Adjusted class weights: {weights}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c49306de",
   "metadata": {},
   "source": [
    "## <a id='model'></a>4. Model (ResNet50)\n",
    "_Load ResNet50 and adapt the final layer to 3 classes._"
   ]
  },
  {
   "cell_type": "code",
   "id": "c70825b8",
   "metadata": {},
   "source": [
    "# Cell 11: Model Definition (3-Class Classification)\n",
    "class ResNet3DClassifier(nn.Module):\n",
    "    def __init__(self, in_channels=5, num_classes=3):  # 5 channels, 3 classes\n",
    "        super().__init__()\n",
    "        self.backbone = resnet50(\n",
    "            pretrained=False,\n",
    "            spatial_dims=3,\n",
    "            n_input_channels=in_channels,\n",
    "            num_classes=512\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.backbone(x)\n",
    "        return self.classifier(features)\n",
    "\n",
    "\n",
    "model = ResNet3DClassifier(in_channels=len(CHANNEL_KEYS), num_classes=NUM_CLASSES).to(device)\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"Model created:\")\n",
    "print(f\"  Total parameters: {total_params:,}\")\n",
    "print(f\"  Trainable parameters: {trainable_params:,}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "9219e88b",
   "metadata": {},
   "source": [
    "## <a id='loss'></a>5. Loss & Optimizer\n",
    "_Define loss, optimizer, scheduler._"
   ]
  },
  {
   "cell_type": "code",
   "id": "dc90bd20",
   "metadata": {},
   "source": [
    "# Cell 12: Optimizer and Scheduler\n",
    "from torch.optim.lr_scheduler import SequentialLR, LinearLR, CosineAnnealingLR\n",
    "\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=LR,  # Changed from INITIAL_LR\n",
    "    weight_decay=WEIGHT_DECAY,\n",
    "    betas=(0.9, 0.999)\n",
    ")\n",
    "\n",
    "# Warmup (3 epochs) + Cosine decay\n",
    "warmup = LinearLR(optimizer, start_factor=0.1, total_iters=3)\n",
    "cosine = CosineAnnealingLR(optimizer, T_max=EPOCHS-3, eta_min=1e-6)\n",
    "scheduler = SequentialLR(optimizer, schedulers=[warmup, cosine], milestones=[3])\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
    "scaler = GradScaler()\n",
    "\n",
    "print(\"Optimizer, scheduler, and loss function ready\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "db58a608",
   "metadata": {},
   "source": [
    "## <a id='eval'></a>7. Evaluation & Metrics (ROC/AUC)\n",
    "_Compute ROC, AUC-macro, accuracy, and operating-point metrics._"
   ]
  },
  {
   "cell_type": "code",
   "id": "336a9fcc",
   "metadata": {},
   "source": [
    "# Cell 13: Evaluation Function\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(loader, epoch, tag=\"Val\"):\n",
    "    model.eval()\n",
    "    running = 0.0\n",
    "    all_logits = []\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    n = 0\n",
    "\n",
    "    pbar = tqdm(loader, desc=f\"{tag} {epoch}\", leave=False)\n",
    "    for batch in pbar:\n",
    "        x = batch[\"image\"].to(device, non_blocking=True)\n",
    "        y = batch[\"label\"].to(device, non_blocking=True).long()\n",
    "\n",
    "        logits = model(x)\n",
    "        loss = criterion(logits, y)\n",
    "\n",
    "        running += loss.item() * x.size(0)\n",
    "        n += x.size(0)\n",
    "\n",
    "        preds = logits.argmax(dim=1)\n",
    "        all_preds.append(preds.detach().cpu().numpy())\n",
    "        all_labels.append(y.detach().cpu().numpy())\n",
    "        all_logits.append(logits.detach().cpu().numpy())\n",
    "\n",
    "        pbar.set_postfix({'loss': running / max(n, 1)})\n",
    "\n",
    "    all_labels = np.concatenate(all_labels) if len(all_labels) else np.array([])\n",
    "    all_logits = np.concatenate(all_logits) if len(all_logits) else np.zeros((0, NUM_CLASSES))\n",
    "    all_preds = np.concatenate(all_preds) if len(all_preds) else np.array([])\n",
    "\n",
    "    # Softmax probabilities for multi-class\n",
    "    probs = torch.softmax(torch.from_numpy(all_logits), dim=1).numpy()\n",
    "\n",
    "    # Accuracy\n",
    "    accuracy = float((all_preds == all_labels).mean()) if len(all_labels) else 0.0\n",
    "\n",
    "    # Macro AUC (OvR) across 3 classes\n",
    "    try:\n",
    "        auc_macro = float(roc_auc_score(all_labels, probs, multi_class=\"ovr\", average=\"macro\"))\n",
    "    except Exception as e:\n",
    "        print(f\"AUC-macro calculation issue: {e}\")\n",
    "        auc_macro = float(\"nan\")\n",
    "\n",
    "    # Operating points for malignant vs rest\n",
    "    spec_at_90sens = float(\"nan\")\n",
    "    sens_at_90spec = float(\"nan\")\n",
    "    if len(all_labels) and NUM_CLASSES >= 3:\n",
    "        y_true_bin = (all_labels == TARGET_CLASS_FOR_OPS).astype(np.uint8)   # malignant vs rest\n",
    "        y_score_bin = probs[:, TARGET_CLASS_FOR_OPS]\n",
    "        if len(np.unique(y_true_bin)) == 2:\n",
    "            fpr, tpr, thr = roc_curve(y_true_bin, y_score_bin)\n",
    "            # Spec@90% Sens\n",
    "            mask_sens = tpr >= 0.90\n",
    "            if np.any(mask_sens):\n",
    "                spec_at_90sens = float(np.max(1.0 - fpr[mask_sens]))\n",
    "            # Sens@90% Spec\n",
    "            mask_spec = (1.0 - fpr) >= 0.90\n",
    "            if np.any(mask_spec):\n",
    "                sens_at_90spec = float(np.max(tpr[mask_spec]))\n",
    "\n",
    "    print(f\"{tag}: loss={running/max(n,1):.4f}, acc={accuracy:.4f}, \"\n",
    "          f\"AUC-macro={auc_macro if not np.isnan(auc_macro) else 'nan'}, \"\n",
    "          f\"Spec@90%Sens={spec_at_90sens if not np.isnan(spec_at_90sens) else 'nan'}, \"\n",
    "          f\"Sens@90%Spec={sens_at_90spec if not np.isnan(sens_at_90spec) else 'nan'}\")\n",
    "\n",
    "    return {\n",
    "        \"loss\": running / max(n, 1),\n",
    "        \"auc_macro\": auc_macro,\n",
    "        \"accuracy\": accuracy,\n",
    "        \"probs\": probs,\n",
    "        \"labels\": all_labels,\n",
    "        \"preds\": all_preds,\n",
    "        \"spec_at_90sens\": spec_at_90sens,\n",
    "        \"sens_at_90spec\": sens_at_90spec,\n",
    "    }\n",
    "\n",
    "print(\"Evaluation function ready\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "dd68337a",
   "metadata": {},
   "source": [
    "# Cell 14: Training Function\n",
    "def train_one_epoch(epoch):\n",
    "    model.train()\n",
    "    running = 0.0\n",
    "    correct = 0\n",
    "    n = 0\n",
    "    pbar = tqdm(train_loader, desc=f\"Train {epoch}\")\n",
    "    \n",
    "    for batch in pbar:\n",
    "        x = batch[\"image\"].to(device, non_blocking=True)\n",
    "        y = batch[\"label\"].to(device, non_blocking=True).long()\n",
    "        \n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        \n",
    "        with autocast(enabled=(device.type == \"cuda\")):\n",
    "            logits = model(x)\n",
    "            loss = criterion(logits, y)\n",
    "        \n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.unscale_(optimizer)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        running += loss.item() * x.size(0)\n",
    "        preds = logits.argmax(dim=1)\n",
    "        correct += (preds == y).sum().item()\n",
    "        n += x.size(0)\n",
    "        \n",
    "        pbar.set_postfix({\n",
    "            'loss': running/max(n,1),\n",
    "            'acc': correct/max(n,1),\n",
    "            'lr': optimizer.param_groups[0]['lr']\n",
    "        })\n",
    "    \n",
    "    scheduler.step()\n",
    "    return running / max(n,1), correct / max(n,1)\n",
    "\n",
    "print(\"Training function ready\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "053ff8f7",
   "metadata": {},
   "source": [
    "# Cell 15a: Initialize Training\n",
    "best_macro_auc = -np.inf\n",
    "best_ckpt = None\n",
    "history = {\n",
    "    'train_loss': [], 'train_acc': [],\n",
    "    'val_loss': [], 'val_auc_macro': [], 'val_spec_at_90sens': [], 'val_sens_at_90spec': [],\n",
    "    'lr': []\n",
    "}\n",
    "\n",
    "print(f\"Starting training for {EPOCHS} epochs\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "70de3ccc",
   "metadata": {},
   "source": [
    "# Cell 15b: Sanity Check Model Outputs\n",
    "print(\"Checking initial model behavior\")\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    sample_batch = next(iter(val_loader))\n",
    "    x = sample_batch[\"image\"].to(device)\n",
    "    y = sample_batch[\"label\"].to(device)\n",
    "    \n",
    "    logits = model(x)\n",
    "    probs = torch.softmax(logits, dim=1)\n",
    "    preds = logits.argmax(dim=1)\n",
    "    \n",
    "    print(f\"Sample batch size: {x.shape[0]}\")\n",
    "    print(f\"True labels: {y.cpu().numpy()}\")\n",
    "    print(f\"Predictions: {preds.cpu().numpy()}\")\n",
    "    print(f\"Class 0 probs: {probs[:, 0].cpu().numpy()}\")\n",
    "    print(f\"Class 1 probs: {probs[:, 1].cpu().numpy()}\")\n",
    "    print(f\"Logits range: [{logits.min().item():.2f}, {logits.max().item():.2f}]\")\n",
    "\n",
    "model.train()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "aa03ff89",
   "metadata": {},
   "source": [
    "## <a id='train'></a>6. Training Loop\n",
    "_Epoch loop, logging, checkpointing best val AUC._"
   ]
  },
  {
   "cell_type": "code",
   "id": "1a74b449",
   "metadata": {},
   "source": [
    "# Cell 16: Training Loop\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    # Train\n",
    "    train_loss, train_acc = train_one_epoch(epoch)\n",
    "\n",
    "    # Validate\n",
    "    val = evaluate(val_loader, epoch, tag=\"Val\")\n",
    "\n",
    "    # Store history\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['val_loss'].append(val['loss'])\n",
    "    history['val_auc_macro'].append(val['auc_macro'])\n",
    "    history['val_spec_at_90sens'].append(val['spec_at_90sens'])\n",
    "    history['val_sens_at_90spec'].append(val['sens_at_90spec'])\n",
    "    history['lr'].append(optimizer.param_groups[0]['lr'])\n",
    "\n",
    "    # Print summary\n",
    "    print(f\"\\nEpoch {epoch}/{EPOCHS}\")\n",
    "    print(f\"  Train: loss={train_loss:.4f}, acc={train_acc:.4f}\")\n",
    "    print(f\"  Val:   loss={val['loss']:.4f}, acc={val['accuracy']:.4f}, \"\n",
    "          f\"AUC-macro={val['auc_macro'] if not np.isnan(val['auc_macro']) else 'nan'}, \"\n",
    "          f\"Spec@90%Sens={val['spec_at_90sens'] if not np.isnan(val['spec_at_90sens']) else 'nan'}, \"\n",
    "          f\"Sens@90%Spec={val['sens_at_90spec'] if not np.isnan(val['sens_at_90spec']) else 'nan'}\")\n",
    "    print(f\"  Val predictions: {np.bincount(val['preds'], minlength=NUM_CLASSES)}\")\n",
    "    print(f\"  LR: {optimizer.param_groups[0]['lr']:.2e}\")\n",
    "\n",
    "    # Save best model by macro AUC\n",
    "    if (val[\"auc_macro\"] == val[\"auc_macro\"]) and (val[\"auc_macro\"] > best_macro_auc):  # NaN-safe\n",
    "        best_macro_auc = val[\"auc_macro\"]\n",
    "        best_ckpt = {\n",
    "            \"state_dict\": {k: v.detach().cpu() for k, v in model.state_dict().items()},\n",
    "            \"epoch\": epoch,\n",
    "            \"val\": val,\n",
    "        }\n",
    "        print(f\"  ✓ New best model (AUC-macro: {best_macro_auc:.4f})\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Training completed!\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "60afb511",
   "metadata": {},
   "source": [
    "# Cell 17: Save Best Model\n",
    "if best_ckpt is not None:\n",
    "    save_path = \"resnet50_classifier_best.pth\"\n",
    "    torch.save(best_ckpt, save_path)\n",
    "    print(f\"Saved best model to {save_path}\")\n",
    "    print(f\"  Best epoch: {best_ckpt['epoch']}\")\n",
    "    print(f\"  Best AUC: {best_macro_auc:.4f}\")\n",
    "else:\n",
    "    print(\"No valid checkpoint to save\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f2f0ea1c",
   "metadata": {},
   "source": [
    "# Cell 18: Save Training History\n",
    "history_df = pd.DataFrame(history)\n",
    "history_df.to_csv(\"training_history_resnet50.csv\", index=False)\n",
    "print(\"Training history saved to training_history_resnet50.csv\")\n",
    "print(\"\\nFinal 5 epochs:\")\n",
    "print(history_df.tail())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "6e10c590",
   "metadata": {},
   "source": [
    "## <a id='plots'></a>8. Plots & Visualization\n",
    "_Training curves and ROC plots._"
   ]
  },
  {
   "cell_type": "code",
   "id": "c26a7029",
   "metadata": {},
   "source": [
    "# Cell 19: Plot Training Curves\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Loss\n",
    "axes[0, 0].plot(history['train_loss'], label='Train Loss', marker='o')\n",
    "axes[0, 0].plot(history['val_loss'], label='Val Loss', marker='s')\n",
    "axes[0, 0].set_title('Training and Validation Loss')\n",
    "axes[0, 0].set_xlabel('Epoch')\n",
    "axes[0, 0].set_ylabel('Loss')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True)\n",
    "\n",
    "# Accuracy\n",
    "axes[0, 1].plot(history['train_acc'], label='Train Acc', marker='o', color='green')\n",
    "axes[0, 1].set_title('Training Accuracy')\n",
    "axes[0, 1].set_xlabel('Epoch')\n",
    "axes[0, 1].set_ylabel('Accuracy')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True)\n",
    "\n",
    "# AUC-macro\n",
    "axes[1, 0].plot(history['val_auc_macro'], label='Val AUC-macro', marker='s', color='purple')\n",
    "axes[1, 0].set_title('Validation AUC-macro')\n",
    "axes[1, 0].set_xlabel('Epoch')\n",
    "axes[1, 0].set_ylabel('AUC')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True)\n",
    "\n",
    "# Learning Rate\n",
    "axes[1, 1].plot(history['lr'], label='Learning Rate', marker='^', color='orange')\n",
    "axes[1, 1].set_title('Learning Rate Schedule')\n",
    "axes[1, 1].set_xlabel('Epoch')\n",
    "axes[1, 1].set_ylabel('LR')\n",
    "axes[1, 1].set_yscale('log')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_history_resnet50.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\" Training curves saved to training_history_resnet50.png\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "03156d85",
   "metadata": {},
   "source": [
    "# Cell 20: Training Summary\n",
    "print(\"Best validation macro AUC:\", best_macro_auc if best_macro_auc == best_macro_auc else \"nan\")\n",
    "if best_ckpt is not None:\n",
    "    print(\"Best epoch:\", best_ckpt[\"epoch\"])\n",
    "    print(\"Best Val metrics:\")\n",
    "    print({k: v for k, v in best_ckpt[\"val\"].items() if k in [\"loss\",\"accuracy\",\"auc_macro\",\"spec_at_90sens\",\"sens_at_90spec\"]})\n",
    "else:\n",
    "    print(\"No checkpoint recorded.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ef1863e5",
   "metadata": {},
   "source": [
    "# Cell 21: ROC Curve Visualization (malignant vs rest)\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"Generating ROC curve (malignant vs rest) from best model\")\n",
    "\n",
    "# Load best model\n",
    "if best_ckpt is not None:\n",
    "    model.load_state_dict(best_ckpt['state_dict'])\n",
    "    model.eval()\n",
    "    \n",
    "    # Get predictions on validation set\n",
    "    all_probs = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_loader, desc=\"ROC Val\", leave=False):\n",
    "            x = batch[\"image\"].to(device, non_blocking=True)\n",
    "            y = batch[\"label\"].to(device, non_blocking=True).long()\n",
    "            logits = model(x)\n",
    "            probs = torch.softmax(logits, dim=1)\n",
    "            all_probs.append(probs[:, TARGET_CLASS_FOR_OPS].detach().cpu().numpy())  # malignant prob\n",
    "            all_labels.append((y == TARGET_CLASS_FOR_OPS).long().detach().cpu().numpy())  # malignant=1 else 0\n",
    "    \n",
    "    all_probs = np.concatenate(all_probs) if len(all_probs) else np.array([])\n",
    "    all_labels = np.concatenate(all_labels) if len(all_labels) else np.array([])\n",
    "    \n",
    "    if len(np.unique(all_labels)) < 2:\n",
    "        print(\"Not enough positive/negative samples in Val for ROC.\")\n",
    "    else:\n",
    "        fpr, tpr, thresholds = roc_curve(all_labels, all_probs)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        \n",
    "        # Threshold by Youden's J statistic (tpr - fpr)\n",
    "        youden = tpr - fpr\n",
    "        optimal_idx = np.argmax(youden)\n",
    "        optimal_threshold = thresholds[optimal_idx]\n",
    "        \n",
    "        plt.figure(figsize=(10, 8))\n",
    "        plt.plot(fpr, tpr, lw=2, label=f'ROC (AUC = {roc_auc:.3f})')\n",
    "        plt.plot([0, 1], [0, 1], lw=2, linestyle='--', label='Random')\n",
    "        \n",
    "        # Mark optimal threshold\n",
    "        plt.scatter(fpr[optimal_idx], tpr[optimal_idx], marker='o', s=100, \n",
    "                    label=f'Threshold={optimal_threshold:.3f}\\nSens={tpr[optimal_idx]:.3f}, Spec={1-fpr[optimal_idx]:.3f}')\n",
    "        \n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate (1 - Specificity)', fontsize=12)\n",
    "        plt.ylabel('True Positive Rate (Sensitivity)', fontsize=12)\n",
    "        plt.title('ROC — Malignant vs Rest (Validation)', fontsize=14)\n",
    "        plt.legend(loc=\"lower right\", fontsize=10)\n",
    "        plt.grid(alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save figure\n",
    "        plt.savefig('roc_curve_malignant_vs_rest.png', dpi=150, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "        # Detailed metrics at optimal threshold\n",
    "        optimal_preds = (all_probs >= optimal_threshold).astype(int)\n",
    "        tn = np.sum((all_labels == 0) & (optimal_preds == 0))\n",
    "        fp = np.sum((all_labels == 0) & (optimal_preds == 1))\n",
    "        fn = np.sum((all_labels == 1) & (optimal_preds == 0))\n",
    "        tp = np.sum((all_labels == 1) & (optimal_preds == 1))\n",
    "        \n",
    "        sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "        f1_score = (2 * precision * sensitivity) / (precision + sensitivity) if (precision + sensitivity) > 0 else 0\n",
    "        \n",
    "        print(\"\\nDetailed metrics at selected threshold:\")\n",
    "        print(f\"  Sensitivity (Recall): {sensitivity:.3f}\")\n",
    "        print(f\"  Specificity:          {specificity:.3f}\")\n",
    "        print(f\"  Precision:            {precision:.3f}\")\n",
    "        print(f\"  F1-Score:             {f1_score:.3f}\")\n",
    "        print(f\"\\nConfusion Matrix at Selected Threshold:\")\n",
    "        print(f\"  True Negatives:  {tn}\")\n",
    "        print(f\"  False Positives: {fp}\")\n",
    "        print(f\"  False Negatives: {fn}\")\n",
    "        print(f\"  True Positives:  {tp}\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        print(\"\\n ROC curve saved to roc_curve_malignant_vs_rest.png\")"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
